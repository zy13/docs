## ☆-虚拟DOM提高性能

- 虚拟 `dom` 相当于在 `js` 和真实 `dom` 中间加了一个缓存，利用 `dom diff` 算法避免了没有必
要的 `dom` 操作，从而提高性能。

- 用 `JavaScript` 对象结构表示 `DOM` 树的结构；然后用这个树构建一个真正的 `DOM` 树，插到文档当中，当状态变更的时候，重新构造一棵新的对象树。

- 然后用新的树和旧的树进行比较，记录两棵树差异：把 `2` 所记录的差异应用到步骤 `1` 所构建的真正的 `DOM` 树上，视图就更新了。

## ☆-Virtual DOM的优势在哪里
### Virtual Dom 的优势

其实这道题目面试官更想听到的答案不是上来就说 **直接操作/频繁操作DOM 的性能差**，如果 `DOM` 操作的性能如此不堪，那么 `jQuery` 也不至于活到今天。

所以面试官更想听到 `VDOM` 想解决的问题，以及为什么频繁的 `DOM` 操作会性能差。

**首先**我们需要知道：

- `DOM` 渲染引擎、`JS` 引擎 相互独立，但又工作在同一线程（主线程） 
- `JS` 代码调用 `DOM API`时，必须挂起 `JS` 引擎，转换传入参数数据、激活 `DOM` 渲染引擎，
- `DOM` 重绘后再转换可能有的返回值，最后激活 `JS` 引擎并继续执行
- 若有频繁的 `DOM API` 调用，且浏览器厂商不做“批量处理”优化， 引擎间切换的单位代价将迅速积累
- 若其中有强制重绘的 `DOM API` 调用，重新计算布局、重新绘制图像会引起更大的性能消耗。

**其次**，**`VDOM` 和真实 `DOM` 的区别和优化**：

- 虚拟 `DOM` 不会立马进行排版与重绘操作
- 虚拟 `DOM` 进行频繁修改，然后一次性比较并修改真实 `DOM` 中需要改的部分，
- 最后在真实`DOM` 中进行排版与重绘，减少过多`DOM`节点排版与重绘损耗
- 虚拟 `DOM` 有效降低大面积真实 `DOM` 的重绘与排版，因为最终与真实 `DOM `比较差异，可以只渲染局部

## ☆-URL和URI的区别
`URI: Uniform Resource Identifier` 指的是**统一资源标识符**

`URL: Uniform Resource Location` 指的是**统一资源定位符**

`URI` 指的是**统一资源标识符**，用唯一的标识来确定一个资源，它是一种抽象的定义，也就是说，不管使用什么方法来定义，只要能唯一的标识一个资源，就可以称为 `URI`。

`URL` 指的是**统一资源定位符**，`URN`指的是统一资源名称。`URL` 和 `URN` 是 `URI` 的子集，`URL` 可以理解为使用地址来标识资源。

## ☆-如何实现图片懒加载

**懒加载**也叫延迟加载，指的是在长网页中延迟加载图片的时机，当用户需要访问时，再去加载，这样可以提高网站的首屏加载速度，提升用户的体验，并且可以减少服务器的压力。

**它适用于图片很多，页面很长的电商网站的场景**。

懒加载的实现**原理**是，将页面上的图片的 `src` 属性设置为空字符串，将图片的真实路径保存在一个自定义属性中，当页面滚动的时候，进行判断，如果图片进入页面可视区域内，则从自定义属性中取出真实路径赋值给图片的 `src` 属性，以此来实现图片的延迟加载。

## ☆-优雅降级和渐进增强
[你能描述一下渐进增强和优雅降级之间的不同吗?（面试题）](https://www.cnblogs.com/iceflorence/archive/2017/03/27/6625466.html#:~:text=%E5%8C%BA%E5%88%AB%EF%BC%9A%E4%BC%98%E9%9B%85%E9%99%8D%E7%BA%A7%E6%98%AF,%E6%9C%AA%E6%9D%A5%E7%8E%AF%E5%A2%83%E7%9A%84%E9%9C%80%E8%A6%81%E3%80%82)

- 扩展 [css-transition](https://developer.mozilla.org/zh-CN/docs/Web/CSS/CSS_Transitions/Using_CSS_transitions)

**渐进增强**( `progressive enhancement`)：针对低版本浏览器进行构建页面，保证最基本的功能，
然后再针对高级浏览器进行效果、交互等改进和追加功能达到更好的用户体验。[扩展](https://www.zhangxinxu.com/wordpress/2010/04/css-%e6%b8%90%e8%bf%9b%e5%a2%9e%e5%bc%ba%e5%9c%a8web%e5%88%b6%e4%bd%9c%e4%b8%ad%e5%b8%b8%e8%a7%81%e5%ba%94%e7%94%a8%e4%b8%be%e4%be%8b/)
```js
.transition{
  -webkit-transition: all .5s;
     -moz-transition: all .5s;
       -o-transition: all .5s;
          transition: all .5s;  
}
```

**优雅降级**(`graceful degradation`) ：一开始就构建完整的功能，然后再针对低版本浏览器进行兼容。
```js
.transition{
　　     transition: all .5s;
　　  -o-transition: all .5s;
  　-moz-transition: all .5s;
 -webkit-transition: all .5s;
}
```
**区别**：
- (1) 优雅降级是从复杂的现状开始，并试图减少用户体验的供给
- (2) 渐进增强则是从一个非常基础的，能够起作用的版本开始，并不断扩充，以适应未来环境的需要
`function foo(){//code... }()`定义预格式文本，保持文本原有的格式
- (3) 降级（功能衰减）意味着往回看；而渐进增强则意味着朝前看，同时保证其根基处于安全地带

## ☆-前端需要注意哪些SEO
- （1）合理的 `title`、`description`、`keywords`：搜索对着三项的权重逐个减小，
  - `title` 值强调重点即可，重要关键词出现不要超过`2`次，而且要靠前，不同页面 `title` 要有所不同；
  - `description` 把页面内容高度 概括，长度合适，不可过分堆砌关键词，不同页面 `description` 有所不同；
  - `keywords` 列举出重要 关键词即可。
- （2）语义化的 `HTML` 代码，符合 `W3C` 规范：语义化代码让搜索引擎容易理解网页。
- （3）重要内容 `HTML` 代码放在最前：搜索引擎抓取 `HTML` 顺序是从上到下，有的搜索引擎对抓取长度有限制，保证重要内容肯定被抓取。
- （4）重要内容不要用 `js` 输出：爬虫不会执行 `js` 获取内容
- （5）少用 `iframe`：搜索引擎不会抓取 `iframe` 中的内容
- （6）非装饰性图片必须加 `alt`
- （7）提高网站速度：网站速度是搜索引擎排序的一个重要指标

## ☆-首屏和白屏时间如何计算

**首屏**时间的计算，可以由 `Native WebView` 提供的类似 `onload` 的方法实现，在 `ios` 下对应的是
`webViewDidFinishLoad`，在 `android` 下对应的是`onPageFinished`事件。

**白屏**的定义有多种。可以认为“没有任何内容”是白屏，可以认为“网络或服务异常”是白屏，可以认为“数据加载中”是白
屏，可以认为“图片加载不出来”是白屏。

场景不同，白屏的计算方式就不相同。
- **方法1**：当页面的元素数小于`x`时，则认为页面白屏。比如“没有任何内容”，可以获取页面的`DOM`
节点数，判断`DOM`节点数少于某个阈值`X`，则认为白屏。 
- **方法2**：当页面出现业务定义的错误码时，则认为是白屏。比如“网络或服务异常”。 
- **方法3**：当页面出现业务定义的特征值时，则认为是白屏。比如“数据加载中”。

## ☆-Cookie的作用和弊端

### cookie作用

- 1.可以在客户端上保存用户数据，起到简单的缓存和用户身份识别等作用。

- 2.保存用户的登陆状态，用户进行登陆，成功登陆后，服务器生成特定的cookie返回给客户端，客户端下次访问该域名下的任何页面，将该cookie的信息发送给服务器，服务器经过检验，来判断用户是否登陆。

- 3.记录用户的行为。

###  cookie弊端
- 1.增加流量消耗，每次请求都需要带上`cookie`信息。
- 2.安全性隐患，`cookie`使用明文传输。如果`cookie`被人拦截了，那人就可以取得所有的`session`信息。
- 3.`Cookie`数量和长度的限制。每个`domain`最多只能有`20`条`cookie`，每个`cookie`长度不能超过`4KB`，否则会被截掉。
- 4.缺乏数据操作接口，浏览器端获取和设置`cookie`只能通过`document.cookie`实现。
## ♥-浏览器输入url到页面呈现出来的过程

![img](../kkb/8-nodejs/imgs/fromURLtoHTMLshow.drawio.png)

- **1、输入 `url` 后，首先需要找到这个 `url` 域名的服务器 `ip`**,
   - **ip** 查找过程：缓存 -> **hosts** -> **DNS**
      - 为了寻找这个 **ip** ，浏览器首先会寻找 **缓存**，查看缓存中是否有记录，缓存的查找记录为：浏览器缓存 -》 系统缓存 -》 路由器缓存，
      - 缓存中没有则查找系统的 **hosts** 文件中是否有记录，
      - 如果没有则查询 **DNS** 服务器，
- **2、得到服务器的`ip`地址后，浏览器根据这个`ip`以及相应的端口号，构造一个 `http` 请求，**
  - 这个**请求报文**会包括这次请求的信息，
    - 主要是请求方法，请求说明和请求附带的数据，
  - 并将这个 **http** 请求封装在一个 **tcp** 包中，
    - 这个 **tcp** 包会依次经过传输层，网络层，数据链路层，物理层到达服务器，
- **3、服务器解析这个请求来作出响应，返回相应的 `html` 给浏览器，**
  - 分析客户端请求
  - 根据分析结果处理业务逻辑
  - 响应处理结果，如返回相应的html
- **4、因为`html`是一个树形结构，浏览器根据这个`html`来构建 `DOM` 树，**
  - 在 **dom** 树的构建过程中如果遇到 **JS** 脚本和外部 **JS** 连接，则会停止构建 **DOM** 树来执行和下载相应的代码，这会造成阻塞，
  - 这就是为什么推荐 **JS** 代码应该放在 **html** 代码的后面，
- **5、之后根据外部样式，内部样式，内联样式构建一个`CSS`对象模型树 `CSSOM` 树，构建完成后和`DOM`树合并为渲染树，**
  - 这里主要做的是排除非视觉节点，比如 **script**， **meta** 标签和排除 **display** 为 **none** 的节点，之后进行布局，
  - 布局主要是确定各个元素的位置和尺寸，
- **6、之后是渲染页面，**
  - 因为 **html** 文件中会含有图片，视频，音频等资源，
  - 在解析 **DOM** 的过程中，遇到这些都会进行并行下载，
  - 浏览器对每个域的并行下载数量有一定的限制，一般是 **4-6** 个，

- **7、当然在这些所有的请求中我们还需要关注的就是缓存，缓存一般通过 `Cache-Control`、`Last-Modify`、`Expires` 等首部字段控制。** 
  - **Cache-Control** 和 **Expires** 的区别在于 
    - **Cache-Control** 使用相对时间，
    - **Expires** 使用的是基于服务器端的绝对时间，
  - 因为存在时差问题，一般采用 **Cache-Control**，
- **8、在请求这些有设置了缓存的数据时，会先查看是否过期，**
  - 如果没有过期则直接使用本地缓存，
  - 过期则请求并在服务器校验文件是否修改，
    - 如果上一次响应设置了 **ETag** 值，会在这次请求的时候作为 **If-None-Match** 的值交给服务器校验，
    - 如果一致，继续校验 **Last-Modified**，没有设置 **ETag** 则直接验证 **Last-Modified**，再决定是否返回 **304**
    
    ![img](./imgs/storage.png)
## ☆-跨域
因为浏览器出于安全考虑，有同源策略。也就是说，如果**协议、域名或者端口**有一个不同就是跨域，
Ajax 请求会失败。防止CSRF攻击。 
### 1.JSONP 
JSONP的原理很简单，就是利用`<script></script>`标签没有跨域限制的漏洞。 通过`<script></script>`标签指向一个需要访问的地址并提供一个回调函数来接收数据当需要通讯时。
```html
<!-- JSONP 使用简单且兼容性不错，但是只限于 get 请求。 -->
<script>
  function jsonp(data) {
    console.log(data)
  }
</script>
```

### 2. CORS
CORS 需要浏览器和后端同时支持。IE 8 和 9 需要通过 `XDomainRequest` 来实现。

### 3. document.domain
该方式只能用于二级域名相同的情况下，比如 a.test.com 和 b.test.com 适用于该方式。只需要给页面添加 document.domain = 'test.com' 表示二级域名都相同就可以实现跨域

### 4. webpack配置proxyTable设置开发环境跨域

### 5. nginx代理跨域

### 6. iframe跨域

### 7. postMessage
这种方式通常用于获取嵌入页面中的第三方页面数据。一个页面发送消息，另一个页面判断来源并接收消息

## ☆-前端性能优化
三个方面来说明前端性能优化：

### 一： webapck优化与开启gzip压缩
- 1.babel-loader用 include 或 exclude来帮我们避免不必要的转译，不转译node_moudules中的js文件 其次在缓存当前转译的js文件，设置
loader: 'babel-loader?cacheDirectory=true' 
- 2.文件采用按需加载等等 
- 3.具体的做法非常简单，只需要你在你的 request headers 中加上这么一句： accept-encoding:gzip 
- 4.图片优化，采用svg图片或者字体图标 
- 5.浏览器缓存机制，它又分为强缓存和协商缓存
### 二：本地存储
从 Cookie 到 Web Storage、IndexedDB 说明一下SessionStorage和localStorage还有cookie的区别和优缺点

### 三：代码优化 
- 1.事件代理 
- 2.事件的节流和防抖 
- 3.页面的回流和重绘 
- 4.EventLoop事件循环机制
- 5.代码优化等等

## ☆-移动端性能优化
- 尽量使用css3动画，开启硬件加速
- 适当使用touch时间代替click时间
- 避免使用css3渐变阴影效果
- 可以用transform: translateZ(0) 来开启硬件加速
- 不滥用float。float在渲染时计算量比较大，尽量减少使用
- 不滥用web字体。web字体需要下载，解析，重绘当前页面
- 合理使用requestAnimationFrame动画代替setTimeout
- css中的属性（css3 transitions、css3 3D transforms、opacity、webGL、video）会触发GUP渲
染，耗电

## ☆-浏览器缓存
缓存可以减少网络 IO 消耗，提高访问速度。

浏览器缓存是一种操作简单、效果显著的前端性能优化手段 

很多时候，大家倾向于将浏览器缓存简单地理解为“HTTP 缓存”。 

但事实上，浏览器缓存机制有四个方面，它们按照获取资源时请求的优先级依次排列如下：
- Memory Cache
- Service Worker Cache
- HTTP Cache
- Push Cache

缓存它又分为强缓存和协商缓存。优先级较高的是强缓存，在命中强缓存失败的情况下，才会走协商缓
存
- **实现强缓存**：过去我们一直用 expires。当服务器返回响应时，在 Response Headers 中将过期时
间写入 expires 字段，现在一般使用Cache-Control 两者同时出现使用Cache-Control
- **协商缓存**：Last-Modified 是一个时间戳，如果我们启用了协商缓存，它会在首次请求时随着
Response Headers 返回：每次请求去判断这个时间戳是否发生变化。从而去决定你是304读取缓
存还是给你返回最新的数据。

## ☆-websocket和ajax轮询

- **websocket**是html5中提出的新的协议，可以实现客户端与服务器的通信，实现服务器的推送功能
- 优点是，只要经过一次连接，就可以连续不断的得到服务器推送消息，节省带宽和服务器端的压力
- **ajax轮询**模拟常连接就是每隔一段时间（0.5s）就向服务器发起ajax请求，查询服务器是否有数据更新
- 缺点就是，每次都要建立HTTP连接，即使需要传输的数据非常少，浪费带宽

## 回流（Reflow）与重绘（Repaint）

**回流**：当我们对 DOM 的修改引发了 DOM 几何尺寸的变化（比如修改元素的宽、高或隐藏元素
等）时，浏览器需要重新计算元素的几何属性（其他元素的几何属性和位置也会因此受到影
响），然后再将计算的结果绘制出来。这个过程就是回流（**也叫重排**）。

**重绘**：当我们对 DOM 的修改导致了样式的变化、却并未影响其几何属性（比如修改了颜色或背
景色）时，浏览器不需重新计算元素的几何属性、直接为该元素绘制新的样式（跳过了上图所示
的回流环节）。这个过程叫做重绘。

**重绘不一定导致回流，回流一定会导致重绘**

硬要比较的话，回流比重绘做的事情更多，带来的开销也更大。但这两个说到底都是吃性能的，
所以都不是什么善茬。我们在开发中，要从代码层面出发，尽可能把回流和重绘的次数最小化



